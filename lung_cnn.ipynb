{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIleuCAjoFD8",
        "outputId": "bc605d95-4cac-4ad6-ef4f-386169f9c2a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__\n",
        "tf.keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0koUcJMJpEBD",
        "outputId": "78d390e1-f14d-4cc9-fc99-45b5780b0087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 271 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('E:/AI Project/LUNG CANCER/trainset',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH4WzfOhpKc3",
        "outputId": "42a304d1-bf28-451a-cc0a-f38f6a30f927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 81 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('E:/AI Project/LUNG CANCER/testset',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAUt4UMPlhLS"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPzPrMckl-hV"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncpqPl69mOac"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_-FZjn_m8gk"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AZeOGCvnNZn"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GtmUlLd26Nq"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p_Zj1Mc3Ko_"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NALksrNQpUlJ"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUj1W4PJptta",
        "outputId": "cff80245-afe9-4cad-a84f-c0047b3b3c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 132ms/step - loss: 0.7742 - accuracy: 0.8118 - val_loss: 0.6121 - val_accuracy: 0.8148\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.5489 - accuracy: 0.8118 - val_loss: 0.4614 - val_accuracy: 0.8148\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.4781 - accuracy: 0.8118 - val_loss: 0.4529 - val_accuracy: 0.8148\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.4592 - accuracy: 0.8118 - val_loss: 0.4295 - val_accuracy: 0.8148\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.4453 - accuracy: 0.8118 - val_loss: 0.4219 - val_accuracy: 0.8148\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.4300 - accuracy: 0.8118 - val_loss: 0.4029 - val_accuracy: 0.8148\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.4391 - accuracy: 0.8118 - val_loss: 0.4117 - val_accuracy: 0.8148\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.4242 - accuracy: 0.8118 - val_loss: 0.3918 - val_accuracy: 0.8148\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.4196 - accuracy: 0.8118 - val_loss: 0.3797 - val_accuracy: 0.8148\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.4145 - accuracy: 0.8118 - val_loss: 0.3718 - val_accuracy: 0.8148\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.4002 - accuracy: 0.8118 - val_loss: 0.3921 - val_accuracy: 0.8148\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.4054 - accuracy: 0.8081 - val_loss: 0.3600 - val_accuracy: 0.8148\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3996 - accuracy: 0.8192 - val_loss: 0.3674 - val_accuracy: 0.8148\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.4197 - accuracy: 0.8192 - val_loss: 0.3521 - val_accuracy: 0.8148\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.3994 - accuracy: 0.8081 - val_loss: 0.3319 - val_accuracy: 0.8148\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3828 - accuracy: 0.8155 - val_loss: 0.3215 - val_accuracy: 0.8148\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.3820 - accuracy: 0.8155 - val_loss: 0.3282 - val_accuracy: 0.8148\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3770 - accuracy: 0.8155 - val_loss: 0.3171 - val_accuracy: 0.8148\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.3835 - accuracy: 0.8192 - val_loss: 0.3042 - val_accuracy: 0.8148\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3480 - accuracy: 0.8118 - val_loss: 0.3013 - val_accuracy: 0.8148\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3472 - accuracy: 0.8118 - val_loss: 0.2940 - val_accuracy: 0.8272\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.3561 - accuracy: 0.8376 - val_loss: 0.3125 - val_accuracy: 0.8519\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.3541 - accuracy: 0.8229 - val_loss: 0.2754 - val_accuracy: 0.8272\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3426 - accuracy: 0.8192 - val_loss: 0.2927 - val_accuracy: 0.8765\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.3394 - accuracy: 0.8524 - val_loss: 0.2634 - val_accuracy: 0.8519\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3432 - accuracy: 0.8229 - val_loss: 0.2809 - val_accuracy: 0.8889\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.3320 - accuracy: 0.8339 - val_loss: 0.2673 - val_accuracy: 0.8272\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3110 - accuracy: 0.8229 - val_loss: 0.2580 - val_accuracy: 0.8765\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.2938 - accuracy: 0.8487 - val_loss: 0.2473 - val_accuracy: 0.8642\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.2870 - accuracy: 0.8487 - val_loss: 0.2470 - val_accuracy: 0.8765\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.2895 - accuracy: 0.8598 - val_loss: 0.2708 - val_accuracy: 0.8642\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3030 - accuracy: 0.8413 - val_loss: 0.2596 - val_accuracy: 0.8642\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.2818 - accuracy: 0.8376 - val_loss: 0.2301 - val_accuracy: 0.8889\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.2660 - accuracy: 0.8782 - val_loss: 0.2200 - val_accuracy: 0.8889\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.2727 - accuracy: 0.8672 - val_loss: 0.2351 - val_accuracy: 0.9136\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.2464 - accuracy: 0.8819 - val_loss: 0.1864 - val_accuracy: 0.8889\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.3032 - accuracy: 0.8708 - val_loss: 0.1952 - val_accuracy: 0.9012\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.2590 - accuracy: 0.8672 - val_loss: 0.1813 - val_accuracy: 0.8889\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.2206 - accuracy: 0.9114 - val_loss: 0.1797 - val_accuracy: 0.8889\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.2295 - accuracy: 0.8893 - val_loss: 0.1786 - val_accuracy: 0.9383\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.2333 - accuracy: 0.9004 - val_loss: 0.1963 - val_accuracy: 0.9136\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.2168 - accuracy: 0.8930 - val_loss: 0.1629 - val_accuracy: 0.9259\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.2184 - accuracy: 0.8967 - val_loss: 0.1652 - val_accuracy: 0.9259\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.1987 - accuracy: 0.8930 - val_loss: 0.1361 - val_accuracy: 0.9506\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.1933 - accuracy: 0.9114 - val_loss: 0.1481 - val_accuracy: 0.9136\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.2183 - accuracy: 0.9225 - val_loss: 0.1528 - val_accuracy: 0.9259\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.1849 - accuracy: 0.9151 - val_loss: 0.1500 - val_accuracy: 0.9259\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.1924 - accuracy: 0.9077 - val_loss: 0.1014 - val_accuracy: 0.9506\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.1868 - accuracy: 0.9188 - val_loss: 0.1299 - val_accuracy: 0.9259\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.1567 - accuracy: 0.9410 - val_loss: 0.1145 - val_accuracy: 0.9753\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2d2bbf0af10>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsSiWEJY1BPB",
        "outputId": "a84178fe-5a5b-4637-88f6-f1b6d8f3a549"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'E:/AI Project/LUNG CANCER/2.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-c34c23cd2276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:/AI Project/LUNG CANCER/2.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    311\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m--> 313\u001b[1;33m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[0;32m    314\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/AI Project/LUNG CANCER/2.jpg'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('E:/AI Project/LUNG CANCER/2.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'Malignant'\n",
        "else:\n",
        "  prediction = 'benign'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED9KB3I54c1i",
        "outputId": "fa917dd9-9498-410e-bd85-b1af7564964e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kML4A5SEWbYo"
      },
      "outputs": [],
      "source": [
        "cnn.save(\"lung.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4O6tq-HWbYo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "7f28fc2c4919c8b222f90485eff14affc33158b31f3e14105f77befe83009876"
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}